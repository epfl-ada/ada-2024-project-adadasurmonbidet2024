{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.utils.results_utils import *\n",
    "from src.utils.data_utils import str_dict_to_values\n",
    "from src.utils.results_utils import *\n",
    "from src.utils.ml_utils import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "English-Speaking    5171\n",
       "Slavic              3983\n",
       "Romance             1847\n",
       "Hispanic             891\n",
       "East Asian           673\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and present the data\n",
    "df_ethnicity = pd.read_csv('data/name_ethnicity.csv')\n",
    "df_ethnicity['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the most frequent special character to the alphabet: 'é', 'è', 'á' and 'í'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_alphabet = 'abcdefghijklmnopqrstuvwxyzéèíá'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vaclav</td>\n",
       "      <td>Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allan</td>\n",
       "      <td>Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kristine</td>\n",
       "      <td>Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matteo</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Isao</td>\n",
       "      <td>East Asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name     Country\n",
       "0    Vaclav      Slavic\n",
       "1     Allan      Slavic\n",
       "2  Kristine      Slavic\n",
       "3    Matteo     Romance\n",
       "4      Isao  East Asian"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ethnicity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for the model with the different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>name_length</th>\n",
       "      <th>vowel_count</th>\n",
       "      <th>consonant_count</th>\n",
       "      <th>a_f</th>\n",
       "      <th>b_f</th>\n",
       "      <th>c_f</th>\n",
       "      <th>d_f</th>\n",
       "      <th>e_f</th>\n",
       "      <th>...</th>\n",
       "      <th>u_l</th>\n",
       "      <th>v_l</th>\n",
       "      <th>w_l</th>\n",
       "      <th>x_l</th>\n",
       "      <th>y_l</th>\n",
       "      <th>z_l</th>\n",
       "      <th>é_l</th>\n",
       "      <th>è_l</th>\n",
       "      <th>í_l</th>\n",
       "      <th>á_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vaclav</td>\n",
       "      <td>Slavic</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allan</td>\n",
       "      <td>Slavic</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kristine</td>\n",
       "      <td>Slavic</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matteo</td>\n",
       "      <td>Romance</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Isao</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name     Country  name_length  vowel_count  consonant_count  a_f  b_f  \\\n",
       "0    Vaclav      Slavic            6            2                4    0    0   \n",
       "1     Allan      Slavic            5            2                3    1    0   \n",
       "2  Kristine      Slavic            8            3                5    0    0   \n",
       "3    Matteo     Romance            6            3                3    0    0   \n",
       "4      Isao  East Asian            4            3                1    0    0   \n",
       "\n",
       "   c_f  d_f  e_f  ...  u_l  v_l  w_l  x_l  y_l  z_l  é_l  è_l  í_l  á_l  \n",
       "0    0    0    0  ...    0    1    0    0    0    0    0    0    0    0  \n",
       "1    0    0    0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2    0    0    0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "3    0    0    0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4    0    0    0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_processor = NameFeatureProcessor('Name', ngram_range = (2,3))\n",
    "\n",
    "df_ml = origin_processor.process(df_ethnicity,alphabet = augmented_alphabet,analyze_name = True, diacritic = False, phonetics = False, first_last = True, ngram=False)\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(analyzer='char', ngram_range=(2, 3), n_features=1000)  \n",
    "ngram_features = vectorizer.fit_transform(df_ml['Name'])\n",
    "n_gram_df = pd.DataFrame(ngram_features.toarray())\n",
    "df_ml = pd.concat([df_ml, n_gram_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hashing_vectorizer_origin.pkl', 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_predictor = PredictorModel_o(df_ml,'Country')\n",
    "df_origin = df_ml.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "rows_with_nans = df_origin.isna().any(axis=1).sum()\n",
    "print(rows_with_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = df_origin.dropna()                      # Drop NaN values\n",
    "df_origin.columns = df_origin.columns.astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      East Asian       0.82      0.77      0.79        73\n",
      "English-Speaking       0.76      0.69      0.72       508\n",
      "        Hispanic       0.44      0.53      0.48        83\n",
      "         Romance       0.55      0.69      0.61       202\n",
      "          Slavic       0.80      0.76      0.78       391\n",
      "\n",
      "        accuracy                           0.71      1257\n",
      "       macro avg       0.68      0.69      0.68      1257\n",
      "    weighted avg       0.72      0.71      0.71      1257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "origin_predictor.train(df_origin, balancing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for a chosen name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  ['Slavic']\n"
     ]
    }
   ],
   "source": [
    "origin_predictor.create_and_predict('aleksander')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for the names of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akooshay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melanie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jericho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bashira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name\n",
       "0  Akooshay\n",
       "1   Melanie\n",
       "2  Williams\n",
       "3   Jericho\n",
       "4   Bashira"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names = pd.read_csv('data/cleaned.csv')\n",
    "to_be_dropped = ['Wikipedia_ID','Languages','Country','Name','Sex','Actor_age','Release_date','Genre_Category']\n",
    "df_names = df_names.drop(columns=to_be_dropped)\n",
    "df_names = df_names\n",
    "df_names.rename(columns={'Character_name': 'Name'}, inplace=True)\n",
    "df_names.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_origin = 'model_Country.pkl'\n",
    "\n",
    "with open(path_origin, 'rb') as file:\n",
    "    predict_origin = pickle.load(file)\n",
    "\n",
    "def feature_creation_o(df_pred):\n",
    "    augmented_alphabet = 'abcdefghijklmnopqrstuvwxyzéèíá'\n",
    "    pred_processor = NameFeatureProcessor('Name',ngram_range=(2,3))\n",
    "    df_pred =pred_processor.process(df_pred,alphabet = augmented_alphabet,analyze_name = True, diacritic = False, phonetics = False, first_last = True, ngram=False)\n",
    "\n",
    "    with open(f'hashing_vectorizer_origin.pkl', 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "\n",
    "    ngram_name = vectorizer.transform(df_pred['Name'])\n",
    "    ngram_name_df = pd.DataFrame(ngram_name.toarray())\n",
    "    df_pred = pd.concat([df_pred, ngram_name_df], axis=1)\n",
    "    return df_pred\n",
    "\n",
    "def predict_one_o(df, model):\n",
    "    df.drop(columns=['Name'],inplace=True)\n",
    "    df.columns = df.columns.astype(str)\n",
    "    return model.predict(df)\n",
    "    \n",
    "def create_and_predict_origin(df, model):\n",
    "    df_save = df.copy()\n",
    "    df = feature_creation_o(df)\n",
    "    pred = predict_one_o(df, model)\n",
    "    df['Name'] = df_save\n",
    "    df['Ethnicity'] = pred\n",
    "\n",
    "    return df[['Name', 'Ethnicity']]  # Return a DataFrame with Name and Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an save the DataFrame\n",
    "df_prediction = create_and_predict_origin(df_names, predict_origin)\n",
    "df_prediction.to_csv('data/movie_character_ethnicity.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
